{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chris\\miniconda3\\envs\\LSTF_Linear\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I want to investigate how this method performs on models with and without alpha. My initial thoughts are that the model with alpha the predictions on average will be better so the scores are lower so the distances are smaller. \n",
    "\n",
    "How does this relate to distribution shift? We are interested in the time series nature of the data and how it deals with it so this still may be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a TS, where the distribution changes at different points deppending on a provided list of distribution shifts.\n",
    "def Create_TimeSeries(s, dist_shifts):\n",
    "    n = s//len(dist_shifts)\n",
    "    m = s%len(dist_shifts)\n",
    "\n",
    "    final = np.array([])\n",
    "    \n",
    "    for i in range(len(dist_shifts)-1):\n",
    "        Y = abs(np.random.normal(dist_shifts[i][0], dist_shifts[i][1], n))\n",
    "        final = np.concatenate((final, Y))\n",
    "    \n",
    "    final = np.concatenate((final, abs(np.random.normal(dist_shifts[-1][0], dist_shifts[-1][1], n+m))))\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will just look at a simple random walk.\n",
    "\n",
    "p = 0.5\n",
    "pdist = [1-p, p]\n",
    "steps = [-1, 1]\n",
    "\n",
    "datapoints = 500\n",
    "seq_length = 300\n",
    "\n",
    "output_label_tuples = []\n",
    "\n",
    "dist_shift = [(0, 1), (-5, 1), (0, 10), (0.1, 0.1)]\n",
    "#dist_shift = [((-1**x) * 100, 100) if x%5==0 else (0, 0) for x in range(30)]\n",
    "\n",
    "for _ in range(datapoints):\n",
    "    X =  np.random.choice(steps, size=seq_length, p=pdist)\n",
    "    Y = Create_TimeSeries(seq_length, dist_shift)\n",
    "    T = np.cumsum(X*Y)\n",
    "    \n",
    "    input_data = T[:-1]\n",
    "    labels_data = T[1:]\n",
    "\n",
    "    output_label_tuples.append((input_data, labels_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Output = output_label_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(x):\n",
    "    add = 0.00\n",
    "    return x + (np.random.choice(steps, len(x), p=[0.5-add, 0.5+add]) * abs(np.random.normal(0, 1, len(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would It not just be better to take the previous value as the thing -> this woudl make more sense but the whole of this technique is that it that should on any model. This is a good test for your models which you have been making as this is a sense where it is impossible to get any on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-cf435876a0fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msimple_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msimple_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0morignal_alpha\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0merror_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0malpha_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-cf435876a0fa>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mweights\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msimple_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msimple_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m         \u001b[0malpha\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0morignal_alpha\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0merror_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     54\u001b[0m         \u001b[0malpha_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "\n",
    "# This function returns the quantile\n",
    "def Q_t(p, scores):\n",
    "    return np.quantile(scores, p)\n",
    "\n",
    "# This function predicts a range of Y_t at the alpha level. By using alpha_t.\n",
    "def C_t(alpha_t, scores, sigma_t, t):\n",
    "    positve_v = (sigma_t) + (abs(sigma_t) * Q_t(1-alpha_t, scores[:t]))\n",
    "    negative_v = (sigma_t) - (abs(sigma_t) * Q_t(1-alpha_t, scores[:t]))\n",
    "    return negative_v, positve_v\n",
    "\n",
    "# This function returns 1 if the prediction lies in the interval, 0 otherwise.\n",
    "def err_t(Y_t, C_t):\n",
    "    if C_t[0] < Y_t < C_t[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def weight(t, i):\n",
    "    return (0.95**(t-i))/np.sum([0.95**(t-j) for j in range(1,t)])\n",
    "\n",
    "def simple_weight(t):\n",
    "    return 5*t\n",
    "    \n",
    "\n",
    "# We have 240 elememts we want a decent approximation of the quantile. So we will start at.\n",
    "inital_window_size = 50\n",
    "alpha = 0.3\n",
    "orignal_alpha = alpha \n",
    "gamma = 0.05\n",
    "\n",
    "\n",
    "total_coverage_list = []\n",
    "\n",
    "for m, (x, y) in enumerate(train_Output):\n",
    "    # Getting the prediction and the actual value.\n",
    "    xpred = Model(x)\n",
    "    # Calculating the scores at each time step\n",
    "    All_scores = (abs(y - xpred))/abs(xpred)\n",
    "\n",
    "    error_list = []\n",
    "    error_part_list = []\n",
    "    Coverage_list = []\n",
    "    alpha_list = []\n",
    "    \n",
    "    for i in range(20, len(All_scores)):\n",
    "        Coverage_t = C_t(alpha, All_scores, xpred[i], i)\n",
    "        Coverage_list.append(Coverage_t)\n",
    "        error_t = err_t(y[i], Coverage_t)\n",
    "        \n",
    "        error_list.append(error_t)\n",
    "        weights = [simple_weight(time) for time in range(1, i-20)] / np.sum([simple_weight(time) for time in range(0, i-20)])\n",
    "        \n",
    "        alpha = min(max(alpha + (gamma * (orignal_alpha - np.sum([weights[l]*error_list[l] for l in range(2,i-20)]))), 0), 1)\n",
    "        alpha_list.append(alpha)\n",
    "\n",
    "    \n",
    "    coverage = 1 - pd.Series(error_list).rolling(50).mean().mean()\n",
    "    total_coverage_list.append(coverage)\n",
    "    \n",
    "    if m<10:\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(30, 10))\n",
    "        \n",
    "        axs[0][0].plot(1 - pd.Series(error_list).rolling(50).mean())\n",
    "        axs[0][0].axhline(coverage, color='r', linestyle='--')\n",
    "        axs[0][0].set_title('Coverage')\n",
    "        \n",
    "        axs[0][1].plot([ele[0] for ele in Coverage_list], label='Lower')\n",
    "        axs[0][1].plot([ele[1] for ele in Coverage_list], label='Upper')\n",
    "        axs[0][1].plot(y[20:])\n",
    "        axs[0][1].set_title('Prediction')\n",
    "        axs[0][1].legend()\n",
    "\n",
    "        axs[1][0].plot([ele[1]-ele[0] for ele in Coverage_list], label='Distance')\n",
    "        axs[1][0].axhline(np.mean([ele[1]-ele[0] for ele in Coverage_list]), color='r', linestyle='--')\n",
    "        axs[1][0].legend()\n",
    "        axs[1][0].set_title('Distance between upper and lower bounds')\n",
    "\n",
    "        axs[1][1].plot(alpha_list)\n",
    "        axs[1][1].set_title('Alpha')\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print('The average coverage is', np.mean(total_coverage_list))\n",
    "\n",
    "# Would be useful to know the average distance between the upper and lower predictions.\n",
    "average_distance = np.mean([ele[1] - ele[0] for ele in Coverage_list])\n",
    "print('The average distance between the upper and lower predictions is', average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in range(1,0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptive is completley hopeless as you would imagine."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTF_Linear",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
