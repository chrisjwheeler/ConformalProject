{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates a TS, where the distribution changes at different points deppending on a provided list of distribution shifts.\n",
    "def Create_TimeSeries(s, dist_shifts):\n",
    "    n = s//len(dist_shifts)\n",
    "    m = s%len(dist_shifts)\n",
    "\n",
    "    final = np.array([])\n",
    "    \n",
    "    for i in range(len(dist_shifts)-1):\n",
    "        Y = abs(np.random.normal(dist_shifts[i][0], dist_shifts[i][1], n))\n",
    "        final = np.concatenate((final, Y))\n",
    "    \n",
    "    final = np.concatenate((final, abs(np.random.normal(dist_shifts[-1][0], dist_shifts[-1][1], n+m))))\n",
    "    \n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we will just look at a simple random walk.\n",
    "\n",
    "p = 0.5\n",
    "pdist = [1-p, p]\n",
    "steps = [-1, 1]\n",
    "\n",
    "datapoints = 10\n",
    "seq_length = 300\n",
    "\n",
    "output_label_tuples = []\n",
    "\n",
    "dist_shift = [ (-10, 1)]\n",
    "#dist_shift = [(0,1), (2,0)]\n",
    "#dist_shift = [((-1**x) * 100, 100) if x%5==0 else (0, 0) for x in range(30)]\n",
    "\n",
    "for _ in range(datapoints):\n",
    "    X =  np.random.choice(steps, size=seq_length, p=pdist)\n",
    "    Y = Create_TimeSeries(seq_length, dist_shift)\n",
    "    T = np.cumsum(X*Y)\n",
    "    \n",
    "    input_data = T[:-1]\n",
    "    labels_data = T[1:]\n",
    "\n",
    "    output_label_tuples.append((input_data, labels_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Output = output_label_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "cannot access local variable 'B_t' where it is not associated with a value",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m ACP \u001b[38;5;241m=\u001b[39m AdaptiveCP(\u001b[38;5;241m0.3\u001b[39m, \u001b[38;5;241m50\u001b[39m )\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_Output):\n\u001b[1;32m----> 6\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mACP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDt_ACI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chris\\Documents\\Conformal_Prediction\\Adapted_Conformal_Prediction\\ConformalMethods.py:152\u001b[0m, in \u001b[0;36mAdaptiveCP.Dt_ACI\u001b[1;34m(self, timeseries_data, gamma_candidates, custom_interval)\u001b[0m\n\u001b[0;32m    149\u001b[0m         B_t \u001b[38;5;241m=\u001b[39m possi\n\u001b[0;32m    150\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 152\u001b[0m B_t_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mB_t\u001b[49m)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Updating the weights.\u001b[39;00m\n\u001b[0;32m    155\u001b[0m new_weights \u001b[38;5;241m=\u001b[39m gamma_weights \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\u001b[38;5;241m-\u001b[39mnu \u001b[38;5;241m*\u001b[39m l_vec(B_t, candiate_alpha[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n",
      "\u001b[1;31mUnboundLocalError\u001b[0m: cannot access local variable 'B_t' where it is not associated with a value"
     ]
    }
   ],
   "source": [
    "from ConformalMethods import AdaptiveCP\n",
    "\n",
    "ACP = AdaptiveCP(0.3, 50 )\n",
    "\n",
    "for i, data in enumerate(train_Output):\n",
    "    a = ACP.Dt_ACI(data)\n",
    "    print(a)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Model(x):\n",
    "    add = 0.00\n",
    "    return x #+ (np.random.choice(steps, len(x), p=[0.5-add, 0.5+add]) * abs(np.random.normal(0, 1, len(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would It not just be better to take the previous value as the thing -> this woudl make more sense but the whole of this technique is that it that should on any model. This is a good test for your models which you have been making as this is a sense where it is impossible to get any on the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inital_window_size = 50\n",
    "alpha = 0.3\n",
    "orignal_alpha = alpha \n",
    "\n",
    "# This function predicts a range of Y_t at the alpha level. By using alpha_t.\n",
    "def C_t(alpha_t, scores, sigma_t, t):\n",
    "    Q = np.quantile(scores[:t], alpha_t)\n",
    "    positve_v = (sigma_t) + (abs(sigma_t) * Q)\n",
    "    negative_v = (sigma_t) - (abs(sigma_t) * Q)\n",
    "    return negative_v, positve_v\n",
    "\n",
    "# This function returns 1 if the prediction lies in the interval, 0 otherwise.\n",
    "def err_t(Y_t, C_t):\n",
    "    if C_t[0] < Y_t < C_t[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def l(B, theta):\n",
    "    return (orignal_alpha * (B - theta)) - min(0, (B - theta))\n",
    "    \n",
    "\n",
    "# We have 240 elememts we want a decent approximation of the quantile. So we will start at.\n",
    "\n",
    "\n",
    "\n",
    "total_coverage_list = []\n",
    "\n",
    "\n",
    "# The hyperparameters for the DtACI model.\n",
    "sigma = 0.1\n",
    "nu = 0.1\n",
    "\n",
    "e = 2.71 #np.e\n",
    "\n",
    "for m, (x, y) in enumerate(train_Output):\n",
    "    break\n",
    "    # Initialising the gamma candidates and the weights.\n",
    "    candiate_gamma = [0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "    candiate_alpha = [[0.1, 0.2, 0.3, 0.4, 0.5]]\n",
    "    gamma_weights = [[1.0 for _ in candiate_gamma]]\n",
    "    \n",
    "    error_list = []\n",
    "    Coverage_list = []\n",
    "    alpha_list = []\n",
    "    \n",
    "    alpha_error_list = []\n",
    "    \n",
    "    xpred = Model(x)\n",
    "    # Calculating the scores at each time step\n",
    "    All_scores = (abs(y - xpred))/abs(xpred)\n",
    "\n",
    "\n",
    "    # New thing to keep track of.\n",
    "    \n",
    "    for i in range(20, len(All_scores)):\n",
    "        # The probability of each gamma from the weights from stept.\n",
    "\n",
    "        Wt = sum(gamma_weights[-1])\n",
    "        gamma_probabilites = [w/Wt for w in gamma_weights[-1]]\n",
    "        \n",
    "        \n",
    "        # Choosing a alpha from the probabilites from the gamma candidates. Then calculating the coverage.\n",
    "        chosen_alpha_t = np.random.choice(candiate_alpha[-1], p=gamma_probabilites)\n",
    "        alpha_list.append(chosen_alpha_t)\n",
    "        Coverage_t = C_t(chosen_alpha_t, All_scores, xpred[i], i)\n",
    "        Coverage_list.append(Coverage_t)\n",
    "\n",
    "        # Updating the weights.\n",
    "        temp = [gamma_weights[j] * np.exp(-nu * l(y[i], candiate_alpha[-1][j])) for j in range(len(candiate_gamma))]\n",
    "        sumW, lenW = sum(temp), len(temp)\n",
    "        gamma_weights.append([(w*(1-sigma)) + sumW*(sigma/lenW) for w in temp])\n",
    "\n",
    "        # Calculating the coverage and error at each time step, for different alpha values.\n",
    "        alphai_errors = [err_t(y[i], C_t(alpha_i, All_scores, xpred[i], i)) for alpha_i in candiate_alpha[-1]]\n",
    "        alpha_error_list.append(alphai_errors)\n",
    "\n",
    "        err_true = err_t(y[i], C_t(chosen_alpha_t, All_scores, xpred[i], i))\n",
    "        error_list.append(err_true)\n",
    "\n",
    "        # Updating the alpha values.\n",
    "        candiate_alpha.append([alpha_i + (gamma_c * (orignal_alpha - alpha_i_err)) for alpha_i, alpha_i_err, gamma_c in zip(candiate_alpha[-1], alphai_errors, candiate_gamma)])\n",
    "        \n",
    "        # Mustgo back and check what beta is.\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    coverage = 1 - pd.Series(error_list).mean()\n",
    "    total_coverage_list.append(coverage)\n",
    "    \n",
    "    if m<10:\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(30, 10))\n",
    "        \n",
    "        print(error_list)\n",
    "        axs[0][0].plot(1 - pd.Series(error_list).rolling(50).mean())\n",
    "        axs[0][0].axhline(coverage, color='r', linestyle='--')\n",
    "        axs[0][0].set_title('Coverage')\n",
    "        \n",
    "        axs[0][1].plot([ele[0] for ele in Coverage_list], label='Lower')\n",
    "        axs[0][1].plot([ele[1] for ele in Coverage_list], label='Upper')\n",
    "        axs[0][1].plot(y[20:])\n",
    "        axs[0][1].set_title('Prediction')\n",
    "        axs[0][1].legend()\n",
    "\n",
    "        axs[1][0].plot([ele[1]-ele[0] for ele in Coverage_list], label='Distance')\n",
    "        axs[1][0].axhline(np.mean([ele[1]-ele[0] for ele in Coverage_list]), color='r', linestyle='--')\n",
    "        axs[1][0].legend()\n",
    "        axs[1][0].set_title('Distance between upper and lower bounds')\n",
    "\n",
    "        axs[1][1].plot(alpha_list)\n",
    "        axs[1][1].set_title('Alpha')\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "#print('The average coverage is', np.mean(total_coverage_list))\n",
    "\n",
    "# Would be useful to know the average distance between the upper and lower predictions.\n",
    "#average_distance = np.mean([ele[1] - ele[0] for ele in Coverage_list])\n",
    "#print('The average distance between the upper and lower predictions is', average_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# THIS code is inefficent as it tracks the weights.\n",
    "inital_window_size = 50\n",
    "alpha = 0.3\n",
    "orignal_alpha = alpha \n",
    "\n",
    "# This function predicts a range of Y_t at the alpha level. By using alpha_t.\n",
    "def C_t(alpha_t, scores, sigma_t, t):\n",
    "    alpha_t = min(1, max(0, alpha_t))\n",
    "    Q = np.quantile(scores[:t], alpha_t)\n",
    "    positve_v = (sigma_t) + (abs(sigma_t) * Q)\n",
    "    negative_v = (sigma_t) - (abs(sigma_t) * Q)\n",
    "    return negative_v, positve_v\n",
    "\n",
    "# This function returns 1 if the prediction lies in the interval, 0 otherwise.\n",
    "def err_t(Y_t, C_t):\n",
    "    if C_t[0] < Y_t < C_t[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def l(B, theta):\n",
    "    return (orignal_alpha * (B - theta)) - min(0, (B - theta))\n",
    "\n",
    "\n",
    "\n",
    "l_vec = np.vectorize(l)\n",
    "    \n",
    "\n",
    "# We have 240 elememts we want a decent approximation of the quantile. So we will start at.\n",
    "\n",
    "\n",
    "\n",
    "total_coverage_list = []\n",
    "\n",
    "\n",
    "# The hyperparameters for the DtACI model.\n",
    "sigma = 0.5\n",
    "nu = 0.01\n",
    "\n",
    "\n",
    "\n",
    "for m, (x, y) in enumerate(train_Output[0:5]):\n",
    "    # Initialising the gamma candidates and the weights.\n",
    "    candiate_gamma = np.array([0.01, 0.02, 0.03, 0.05, 0.1])\n",
    "    candiate_alpha = np.array([[orignal_alpha for _ in candiate_gamma]])\n",
    "    gamma_weights = np.array([[1.0 for _ in candiate_gamma]])\n",
    "    \n",
    "    error_list = []\n",
    "    Coverage_list = []\n",
    "    alpha_list = []\n",
    "    \n",
    "    alpha_error_list = []\n",
    "    \n",
    "    xpred = Model(x)\n",
    "    # Calculating the scores at each time step\n",
    "    All_scores = (abs(y - xpred))/abs(xpred)\n",
    "\n",
    "\n",
    "    # New thing to keep track of.\n",
    "    \n",
    "    for i in range(20, len(All_scores)):\n",
    "        # The probability of each gamma from the weights from stept.\n",
    "        Wt = sum(gamma_weights[-1])\n",
    "        gamma_probabilites = gamma_weights[-1]/Wt\n",
    "        \n",
    "        # Choosing a alpha from the probabilites from the gamma candidates. Then calculating the coverage.\n",
    "        chosen_alpha_t = np.random.choice(candiate_alpha[-1], p=gamma_probabilites)\n",
    "        alpha_list.append(chosen_alpha_t)\n",
    "        Coverage_t = C_t(chosen_alpha_t, All_scores, xpred[i], i)\n",
    "        Coverage_list.append(Coverage_t)\n",
    "\n",
    "        # We need to calculate B_t, which is the smallest value such that the obseved value is within the interval.\n",
    "        for possi in np.linspace(0, 1, 1000):\n",
    "            Cpossi= C_t(possi, All_scores, xpred[i], i)\n",
    "            if Cpossi[0] < y[i] < Cpossi[1]:\n",
    "                B_t = possi\n",
    "                break\n",
    "\n",
    "        \n",
    "        # Updating the weights.\n",
    "        new_weights = gamma_weights * np.exp(-nu * l_vec(B_t, candiate_alpha[-1]))\n",
    "        sumW, lenW = sum(new_weights), len(new_weights)\n",
    "        final_weights = new_weights*(1-sigma) + sumW*(sigma/lenW)\n",
    "        gamma_weights = np.vstack((gamma_weights, final_weights))\n",
    "\n",
    "        # Calculating the coverage and error at each time step, for different alpha values.\n",
    "        alphai_errors = np.array([err_t(y[i], C_t(alpha_i, All_scores, xpred[i], i)) for alpha_i in candiate_alpha[-1]])\n",
    "        alpha_error_list.append(alphai_errors)\n",
    "\n",
    "        err_true = err_t(y[i], C_t(chosen_alpha_t, All_scores, xpred[i], i))\n",
    "        error_list.append(err_true)\n",
    "\n",
    "        # Updating the alpha values.\n",
    "        new_alphas = candiate_alpha[-1] + (candiate_gamma * (orignal_alpha - alphai_errors))\n",
    "        candiate_alpha = np.vstack((candiate_alpha, new_alphas))\n",
    "\n",
    "        #plt.plot(alpha_list)\n",
    "        #plt.show()\n",
    "        \n",
    "        # Mustgo back and check what beta is.\n",
    "    \n",
    "    coverage = 1 - pd.Series(error_list).mean()\n",
    "    total_coverage_list.append(coverage)\n",
    "    \n",
    "    if m<10:\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(30, 10))\n",
    "        \n",
    "        print(error_list)\n",
    "        axs[0][0].plot(1 - pd.Series(error_list).rolling(5).mean())\n",
    "        axs[0][0].axhline(coverage, color='r', linestyle='--')\n",
    "        axs[0][0].set_title('Coverage')\n",
    "        \n",
    "        axs[0][1].plot([ele[0] for ele in Coverage_list], label='Lower')\n",
    "        axs[0][1].plot([ele[1] for ele in Coverage_list], label='Upper')\n",
    "        axs[0][1].plot(y[20:])\n",
    "        axs[0][1].set_title('Prediction')\n",
    "        axs[0][1].legend()\n",
    "\n",
    "        axs[1][0].plot([ele[1]-ele[0] for ele in Coverage_list], label='Distance')\n",
    "        axs[1][0].axhline(np.mean([ele[1]-ele[0] for ele in Coverage_list]), color='r', linestyle='--')\n",
    "        axs[1][0].legend()\n",
    "        axs[1][0].set_title('Distance between upper and lower bounds')\n",
    "\n",
    "        axs[1][1].plot(alpha_list)\n",
    "        axs[1][1].set_title('Alpha')\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print('The average coverage is', np.mean(total_coverage_list))\n",
    "\n",
    "# Would be useful to know the average distance between the upper and lower predictions.\n",
    "average_distance = np.mean([ele[1] - ele[0] for ele in Coverage_list])\n",
    "print('The average distance between the upper and lower predictions is', average_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This one is working but is not very accurate. Likley still a mistake in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Havent really been able to replicate results. Likely still an error somewhere, it performs way worse if not choosing randomly. Should compare directly to the simple method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 122\u001b[0m\n\u001b[0;32m    118\u001b[0m         axs[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m    119\u001b[0m         axs[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlpha\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 122\u001b[0m         \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe average coverage is\u001b[39m\u001b[38;5;124m'\u001b[39m, np\u001b[38;5;241m.\u001b[39mmean(total_coverage_list))\n\u001b[0;32m    128\u001b[0m \u001b[38;5;66;03m# Would be useful to know the average distance between the upper and lower predictions.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\pyplot.py:527\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    484\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[0;32m    485\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    526\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[1;32m--> 527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib_inline\\backend_inline.py:90\u001b[0m, in \u001b[0;36mshow\u001b[1;34m(close, block)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m figure_manager \u001b[38;5;129;01min\u001b[39;00m Gcf\u001b[38;5;241m.\u001b[39mget_all_fig_managers():\n\u001b[1;32m---> 90\u001b[0m         \u001b[43mdisplay\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fetch_figure_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfigure_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     95\u001b[0m     show\u001b[38;5;241m.\u001b[39m_to_draw \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\display_functions.py:298\u001b[0m, in \u001b[0;36mdisplay\u001b[1;34m(include, exclude, metadata, transient, display_id, raw, clear, *objs, **kwargs)\u001b[0m\n\u001b[0;32m    296\u001b[0m     publish_display_data(data\u001b[38;5;241m=\u001b[39mobj, metadata\u001b[38;5;241m=\u001b[39mmetadata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    297\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 298\u001b[0m     format_dict, md_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minclude\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m format_dict:\n\u001b[0;32m    300\u001b[0m         \u001b[38;5;66;03m# nothing to display (e.g. _ipython_display_ took over)\u001b[39;00m\n\u001b[0;32m    301\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\formatters.py:182\u001b[0m, in \u001b[0;36mDisplayFormatter.format\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    180\u001b[0m md \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# FIXME: log the exception\u001b[39;00m\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[0;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[1;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\formatters.py:226\u001b[0m, in \u001b[0;36mcatch_format_error\u001b[1;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"show traceback on failed format call\"\"\"\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 226\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;66;03m# don't warn on NotImplementedErrors\u001b[39;00m\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_return(\u001b[38;5;28;01mNone\u001b[39;00m, args[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\formatters.py:343\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    341\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mprinter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# Finally look for special method names\u001b[39;00m\n\u001b[0;32m    345\u001b[0m method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\pylabtools.py:152\u001b[0m, in \u001b[0;36mprint_figure\u001b[1;34m(fig, fmt, bbox_inches, base64, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase\n\u001b[0;32m    150\u001b[0m     FigureCanvasBase(fig)\n\u001b[1;32m--> 152\u001b[0m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbytes_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    153\u001b[0m data \u001b[38;5;241m=\u001b[39m bytes_io\u001b[38;5;241m.\u001b[39mgetvalue()\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fmt \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\backend_bases.py:2167\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[0;32m   2165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bbox_inches:\n\u001b[0;32m   2166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 2167\u001b[0m         bbox_inches \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2168\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox_extra_artists\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2169\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(layout_engine, ConstrainedLayoutEngine) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m   2170\u001b[0m                 pad_inches \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m   2171\u001b[0m             h_pad \u001b[38;5;241m=\u001b[39m layout_engine\u001b[38;5;241m.\u001b[39mget()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh_pad\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\_api\\deprecation.py:454\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    449\u001b[0m     warn_deprecated(\n\u001b[0;32m    450\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    451\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    452\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    453\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 454\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\figure.py:1774\u001b[0m, in \u001b[0;36mFigureBase.get_tightbbox\u001b[1;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[0;32m   1771\u001b[0m     artists \u001b[38;5;241m=\u001b[39m bbox_extra_artists\n\u001b[0;32m   1773\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[1;32m-> 1774\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_tightbbox\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1775\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1776\u001b[0m         bb\u001b[38;5;241m.\u001b[39mappend(bbox)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\legend.py:1072\u001b[0m, in \u001b[0;36mLegend.get_tightbbox\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_tightbbox\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1071\u001b[0m     \u001b[38;5;66;03m# docstring inherited\u001b[39;00m\n\u001b[1;32m-> 1072\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_legend_box\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\offsetbox.py:401\u001b[0m, in \u001b[0;36mOffsetBox.get_window_extent\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m    399\u001b[0m bbox \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_bbox(renderer)\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:  \u001b[38;5;66;03m# Some subclasses redefine get_offset to take no args.\u001b[39;00m\n\u001b[1;32m--> 401\u001b[0m     px, py \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_offset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    403\u001b[0m     px, py \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_offset()\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\offsetbox.py:60\u001b[0m, in \u001b[0;36m_compat_get_offset.<locals>.get_offset\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     56\u001b[0m params \u001b[38;5;241m=\u001b[39m _api\u001b[38;5;241m.\u001b[39mselect_matching_signature(sigs, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     57\u001b[0m bbox \u001b[38;5;241m=\u001b[39m (params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m params \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[0;32m     58\u001b[0m         Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m-\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxdescent\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m-\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mydescent\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     59\u001b[0m                          params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m\"\u001b[39m], params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheight\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m---> 60\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mself\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrenderer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\offsetbox.py:312\u001b[0m, in \u001b[0;36mOffsetBox.get_offset\u001b[1;34m(self, bbox, renderer)\u001b[0m\n\u001b[0;32m    297\u001b[0m \u001b[38;5;129m@_compat_get_offset\u001b[39m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_offset\u001b[39m(\u001b[38;5;28mself\u001b[39m, bbox, renderer):\n\u001b[0;32m    299\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    300\u001b[0m \u001b[38;5;124;03m    Return the offset as a tuple (x, y).\u001b[39;00m\n\u001b[0;32m    301\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;124;03m    renderer : `.RendererBase` subclass\u001b[39;00m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 312\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_offset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset)\n\u001b[0;32m    314\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_offset)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\legend.py:738\u001b[0m, in \u001b[0;36mLegend._findoffset\u001b[1;34m(self, width, height, xdescent, ydescent, renderer)\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Helper function to locate the legend.\"\"\"\u001b[39;00m\n\u001b[0;32m    737\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loc \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:  \u001b[38;5;66;03m# \"best\".\u001b[39;00m\n\u001b[1;32m--> 738\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_best_position\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loc \u001b[38;5;129;01min\u001b[39;00m Legend\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mvalues():  \u001b[38;5;66;03m# Fixed location.\u001b[39;00m\n\u001b[0;32m    740\u001b[0m     bbox \u001b[38;5;241m=\u001b[39m Bbox\u001b[38;5;241m.\u001b[39mfrom_bounds(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, width, height)\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\legend.py:1186\u001b[0m, in \u001b[0;36mLegend._find_best_position\u001b[1;34m(self, width, height, renderer, consider)\u001b[0m\n\u001b[0;32m   1183\u001b[0m badness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;66;03m# XXX TODO: If markers are present, it would be good to take them\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;66;03m# into account when checking vertex overlaps in the next line.\u001b[39;00m\n\u001b[1;32m-> 1186\u001b[0m badness \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlegendBox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_contains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1187\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mline\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mlines\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1188\u001b[0m            \u001b[38;5;241m+\u001b[39m legendBox\u001b[38;5;241m.\u001b[39mcount_contains(offsets)\n\u001b[0;32m   1189\u001b[0m            \u001b[38;5;241m+\u001b[39m legendBox\u001b[38;5;241m.\u001b[39mcount_overlaps(bboxes)\n\u001b[0;32m   1190\u001b[0m            \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(line\u001b[38;5;241m.\u001b[39mintersects_bbox(legendBox, filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1191\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines))\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m badness \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m l, b\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\legend.py:1186\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1183\u001b[0m badness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   1184\u001b[0m \u001b[38;5;66;03m# XXX TODO: If markers are present, it would be good to take them\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m \u001b[38;5;66;03m# into account when checking vertex overlaps in the next line.\u001b[39;00m\n\u001b[1;32m-> 1186\u001b[0m badness \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28msum\u001b[39m(\u001b[43mlegendBox\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcount_contains\u001b[49m\u001b[43m(\u001b[49m\u001b[43mline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvertices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1187\u001b[0m                \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines)\n\u001b[0;32m   1188\u001b[0m            \u001b[38;5;241m+\u001b[39m legendBox\u001b[38;5;241m.\u001b[39mcount_contains(offsets)\n\u001b[0;32m   1189\u001b[0m            \u001b[38;5;241m+\u001b[39m legendBox\u001b[38;5;241m.\u001b[39mcount_overlaps(bboxes)\n\u001b[0;32m   1190\u001b[0m            \u001b[38;5;241m+\u001b[39m \u001b[38;5;28msum\u001b[39m(line\u001b[38;5;241m.\u001b[39mintersects_bbox(legendBox, filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1191\u001b[0m                  \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines))\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m badness \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m   1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m l, b\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\transforms.py:583\u001b[0m, in \u001b[0;36mBboxBase.count_contains\u001b[1;34m(self, vertices)\u001b[0m\n\u001b[0;32m    580\u001b[0m vertices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(vertices)\n\u001b[0;32m    581\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(invalid\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m    582\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin \u001b[38;5;241m<\u001b[39m vertices) \u001b[38;5;241m&\u001b[39m\n\u001b[1;32m--> 583\u001b[0m              (vertices \u001b[38;5;241m<\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m))\u001b[38;5;241m.\u001b[39mall(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msum())\n",
      "File \u001b[1;32mc:\\Python312\\Lib\\site-packages\\matplotlib\\transforms.py:327\u001b[0m, in \u001b[0;36mBboxBase.max\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The bottom-left corner of the bounding box.\"\"\"\u001b[39;00m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_points(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    328\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    329\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The top-right corner of the bounding box.\"\"\"\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_points(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "inital_window_size = 50\n",
    "alpha = 0.1\n",
    "orignal_alpha = alpha \n",
    "\n",
    "# This function predicts a range of Y_t at the alpha level. By using alpha_t.\n",
    "def C_t(alpha_t, scores, sigma_t, t):\n",
    "    alpha_t = min(1, max(0, alpha_t))\n",
    "    Q = np.quantile(scores[:t], 1 - alpha_t)\n",
    "    positve_v = (sigma_t) + (abs(sigma_t) * Q)\n",
    "    negative_v = (sigma_t) - (abs(sigma_t) * Q)\n",
    "    return negative_v, positve_v\n",
    "\n",
    "# This function returns 1 if the prediction lies in the interval, 0 otherwise.\n",
    "def err_t(Y_t, C_t):\n",
    "    if C_t[0] < Y_t < C_t[1]:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "def l(B, theta):\n",
    "    return (orignal_alpha * (B - theta)) - min(0, (B - theta))\n",
    "l_vec = np.vectorize(l)\n",
    "    \n",
    "total_coverage_list = []\n",
    "\n",
    "\n",
    "# The hyperparameters for the DtACI model.\n",
    "sigma = 0.05\n",
    "nu = 0.1\n",
    "\n",
    "for m, (x, y) in enumerate(train_Output[0:5]):\n",
    "    # Initialising the gamma candidates and the weights.\n",
    "    candiate_gamma = np.array([0.001, 0.002, 0.004, 0.008, 0.016, 0.032, 0.064, 0.128])\n",
    "    candiate_alpha = np.array([[orignal_alpha for _ in candiate_gamma]])\n",
    "    gamma_weights = np.array([np.random.random() for _ in candiate_gamma])\n",
    "    \n",
    "    error_list = []\n",
    "    Coverage_list = []\n",
    "    alpha_list = []\n",
    "    alpha_error_list = []\n",
    "    B_t_list = []\n",
    "    \n",
    "    xpred = Model(x)\n",
    "    \n",
    "    # Calculating the scores at each time step\n",
    "    All_scores = (abs(y - xpred))/abs(xpred)\n",
    "\n",
    "\n",
    "    for i in range(20, len(All_scores)):\n",
    "        # The probability of each gamma from the weights from step t.\n",
    "        Wt = gamma_weights.sum()\n",
    "        gamma_probabilites = gamma_weights/Wt\n",
    "        \n",
    "        # Choosing a alpha from the probabilites from the gamma candidates. Then calculating the coverage.\n",
    "        #chosen_alpha_t = np.random.choice(candiate_alpha[-1], p=gamma_probabilites)\n",
    "        chosen_alpha_t = sum(gamma_probabilites * candiate_alpha[-1])\n",
    "        alpha_list.append(chosen_alpha_t)\n",
    "        \n",
    "        Coverage_t = C_t(chosen_alpha_t, All_scores, xpred[i], i)\n",
    "        Coverage_list.append(Coverage_t)\n",
    "        err_true = err_t(y[i], Coverage_t)\n",
    "        error_list.append(err_true)\n",
    "\n",
    "        # TIME FRONTIER -------\n",
    "\n",
    "        # B is the sig level, we want the smallest one so that y is just in it.\n",
    "        for possi in abs(np.linspace(-1, 0, 1000)):\n",
    "            Cpossi= C_t(possi, All_scores, xpred[i], i)\n",
    "            if Cpossi[0] < y[i] < Cpossi[1]:\n",
    "                B_t = possi\n",
    "                break\n",
    "        \n",
    "        B_t_list.append(B_t)\n",
    "        \n",
    "        \n",
    "        # Updating the weights.\n",
    "        new_weights = gamma_weights * np.exp(-nu * l_vec(B_t, candiate_alpha[-1]))\n",
    "        sumW, lenW = sum(new_weights), i\n",
    "        final_weights = new_weights*(1-sigma) + sumW*(sigma/lenW)\n",
    "        gamma_weights = final_weights\n",
    "\n",
    "        # Calculating the coverage and error at each time step, for different alpha values.\n",
    "        alphai_errors = np.array([err_t(y[i], C_t(alpha_i, All_scores, xpred[i], i)) for alpha_i in candiate_alpha[-1]])\n",
    "        alpha_error_list.append(alphai_errors)\n",
    "\n",
    "\n",
    "        # Updating the alpha values.\n",
    "        new_alphas = candiate_alpha[-1] + (candiate_gamma * (orignal_alpha - alphai_errors))\n",
    "        candiate_alpha = np.vstack((candiate_alpha, new_alphas))\n",
    "\n",
    "    \n",
    "    # Making the plots\n",
    "\n",
    "    coverage = 1 - pd.Series(error_list).rolling(50).mean().mean()\n",
    "    total_coverage_list.append(coverage)\n",
    "    \n",
    "    if m<10:\n",
    "        fig, axs = plt.subplots(2, 2, figsize=(30, 10))\n",
    "        \n",
    "        print(error_list)\n",
    "        axs[0][0].plot(1 - pd.Series(error_list).rolling(5).mean())\n",
    "        axs[0][0].axhline(coverage, color='r', linestyle='--')\n",
    "        axs[0][0].set_title('Coverage')\n",
    "        \n",
    "        axs[0][1].plot([ele[0] for ele in Coverage_list], label='Lower')\n",
    "        axs[0][1].plot([ele[1] for ele in Coverage_list], label='Upper')\n",
    "        axs[0][1].plot(y[20:])\n",
    "        axs[0][1].set_title('Prediction')\n",
    "        axs[0][1].legend()\n",
    "\n",
    "        axs[1][0].plot([ele[1]-ele[0] for ele in Coverage_list], label='Distance')\n",
    "        axs[1][0].axhline(np.mean([ele[1]-ele[0] for ele in Coverage_list]), color='r', linestyle='--')\n",
    "        axs[1][0].legend()\n",
    "        axs[1][0].set_title('Distance between upper and lower bounds')\n",
    "\n",
    "        axs[1][1].plot(alpha_list,label='our alpha')\n",
    "        axs[1][1].plot(B_t_list, label='alpha*')\n",
    "        axs[1][1].legend()\n",
    "        axs[1][1].set_title('Alpha')\n",
    "\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "print('The average coverage is', np.mean(total_coverage_list))\n",
    "\n",
    "# Would be useful to know the average distance between the upper and lower predictions.\n",
    "average_distance = np.mean([ele[1] - ele[0] for ele in Coverage_list])\n",
    "print('The average distance between the upper and lower predictions is', average_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(candiate_alpha)\n",
    "print(alpha_error_list) # There is an instance when the alpha error list is not all the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inital_window_size = 50\n",
    "# orignal_alpha = 0.3\n",
    "\n",
    "# # This function predicts a range of Y_t at the alpha level. By using alpha_t.\n",
    "# def C_t(alpha_t, scores, sigma_t, t):\n",
    "#     alpha_t = min(1, max(0, alpha_t))\n",
    "#     Q = np.quantile(scores[:t], 1 - alpha_t)\n",
    "#     positve_v = (sigma_t) + (abs(sigma_t) * Q)\n",
    "#     negative_v = (sigma_t) - (abs(sigma_t) * Q)\n",
    "#     return negative_v, positve_v\n",
    "\n",
    "# # This function returns 1 if the prediction lies in the interval, 0 otherwise.\n",
    "# def err_t(Y_t, C_t):\n",
    "#     if C_t[0] < Y_t < C_t[1]:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "    \n",
    "# def l(B, theta):\n",
    "#     return (orignal_alpha * (B - theta)) - min(0, (B - theta))\n",
    "# l_vec = np.vectorize(l)\n",
    "    \n",
    "# total_coverage_list = []\n",
    "\n",
    "\n",
    "# # The hyperparameters for the DtACI model.\n",
    "# sigma = 0.5\n",
    "# nu = 0.3\n",
    "\n",
    "# for m, (x, y) in enumerate(train_Output[0:1]):\n",
    "#     error_list = []\n",
    "#     Coverage_list = []\n",
    "#     alpha_list = []\n",
    "    \n",
    "#     alpha_error_list = []\n",
    "\n",
    "#     # The first x is the guess for the first y.\n",
    "\n",
    "#     # Initialising the gamma candidates and the weights.\n",
    "\n",
    "#     # These are the expert gammas.\n",
    "#     candiate_gamma = np.array([0.01, 0.02, 0.03, 0.05, 0.1])\n",
    "#     # We are essentialy running ACI multiple times and will evaluate the performance of each gamma.\n",
    "#     candiate_alpha = np.array([[orignal_alpha for _ in candiate_gamma]])\n",
    "#     # The weights for each gamma.\n",
    "#     gamma_weights = np.array([1 for _ in candiate_gamma])\n",
    "\n",
    "#     for i in range(0, len(x)):\n",
    "#         # The probabilites at time t.\n",
    "#         Wt = gamma_weights.sum()\n",
    "#         gamma_probabilites = gamma_weights/Wt\n",
    "        \n",
    "#         ## We will remove the randomness\n",
    "#         chosen_alpha_t = sum(gamma_probabilites * candiate_alpha[-1])\n",
    "#         alpha_list.append(chosen_alpha_t)\n",
    "\n",
    "#         Coverage_t = C_t(chosen_alpha_t, x, x[i], i)\n",
    "#         Coverage_list.append(Coverage_t)\n",
    "#         err_true = err_t(y[i], Coverage_t)\n",
    "#         error_list.append(err_true)\n",
    "#         # TIME FRONTEIR WE HAVE CHOSEN ALPHA SO CAN ACCSESS THE TRUE Y.\n",
    "        \n",
    "\n",
    "#         # We need to calculate B_t, which is the smallest value such that the obseved value is within the interval.\n",
    "#         for possi in np.linspace(0, 1, 1000):\n",
    "#             Cpossi= C_t(possi, x, x[i], i)\n",
    "#             if Cpossi[0] < y[i] < Cpossi[1]:\n",
    "#                 B_t = possi\n",
    "#                 break\n",
    "\n",
    "        \n",
    "#         # Updating the weights.\n",
    "#         new_weights = gamma_weights * np.exp(-nu * l_vec(B_t, candiate_alpha[-1]))\n",
    "#         sumW, lenW = sum(new_weights), i\n",
    "#         final_weights = new_weights*(1-sigma) + sumW*(sigma/lenW)\n",
    "#         gamma_weights = final_weights\n",
    "\n",
    "#         # Calculating the coverage and error at each time step, for different alpha values.\n",
    "#         alphai_errors = np.array([err_t(y[i], C_t(alpha_i, x, x[i], i)) for alpha_i in candiate_alpha[-1])\n",
    "#         alpha_error_list.append(alphai_errors)\n",
    "\n",
    "\n",
    "#         # Updating the alpha values.\n",
    "#         new_alphas = candiate_alpha[-1] + (candiate_gamma * (orignal_alpha - alphai_errors))\n",
    "#         candiate_alpha = np.vstack((candiate_alpha, new_alphas))\n",
    "\n",
    "#         #plt.plot(alpha_list)\n",
    "#         #plt.show()\n",
    "        \n",
    "#         # Mustgo back and check what beta is.\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "#     # Calculating the scores at each time step\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTF_Linear",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
