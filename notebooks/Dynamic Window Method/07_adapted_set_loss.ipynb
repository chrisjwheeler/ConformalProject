{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yahooquery as yq\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "src_path = os.path.abspath(os.path.join('..', '..', 'src'))\n",
    "sys.path.append(src_path)\n",
    "\n",
    "from ConformalMethods import AdaptiveCP, ACP_plots, ACP_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the new proposed set loss function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to see how the new method performs compared to the old one. \n",
    "\n",
    "What I am interested in:\n",
    "- How the coverage and width differs.\n",
    "- If the new loss allows the model to learn better, as in it is choosing the most performant head.\n",
    "        - How will I know what the most performant head is -> I still havent sorted this out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try on both stock data and on normal data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_data(start_index, end_index):\n",
    "    # Open txt file containg ticker names\n",
    "    with open(r'C:\\Users\\tobyw\\Documents\\ChrisPython\\ConformalProject\\scripts\\snptickers.txt', 'r') as f:\n",
    "        all_tickers = f.read().splitlines()\n",
    "        all_tickers.sort()\n",
    "    \n",
    "    stock_tickers = all_tickers[start_index:end_index]\n",
    "\n",
    "    tickers = yq.Ticker(stock_tickers)\n",
    "    all_price_data = tickers.history(period='5y', interval='1d')\n",
    "    price_df = all_price_data[['close']].copy()\n",
    "\n",
    "    stock_data_tuples = []\n",
    "\n",
    "    # Some tickers in the list are incorrect or not trading so need \n",
    "\n",
    "    for ticker_symbol in price_df.index.get_level_values(0).unique():\n",
    "        # Getting the volatilty data for each ticker\n",
    "        ticker_price_data = price_df.loc[ticker_symbol]\n",
    "        ticker_close = ticker_price_data['close'].to_numpy()\n",
    "\n",
    "        # As when creating the volaility there is an intial NaN value, I will remove this.\n",
    "        ticker_close = ticker_close[1:]\n",
    "\n",
    "        # Appending it to the stock_data_tuples list, the last volatilty is used as the prediciton for the next.\n",
    "        stock_data_tuples.append((ticker_close[:-1], ticker_close[1:]))\n",
    "    \n",
    "\n",
    "    return stock_data_tuples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_data = get_stock_data(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_data = ACP_data.random_multi_shift(100, (1300,1301))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The new Set method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define the class with the new set_loss_function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inverse_AdaptedCP(AdaptiveCP):\n",
    "    def set_loss(self, optimal_set, given_set):\n",
    "        # If the optimal set is somehow 0, then we will return the given set.\n",
    "        if optimal_set == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            val = (optimal_set - given_set) / optimal_set\n",
    "         \n",
    "        if val < 0:\n",
    "            return (self.coverage_target) * (-1* val)\n",
    "        else:\n",
    "            return (1 - self.coverage_target) * np.log(1/(1-val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initilising each model.\n",
    "target = 0.1\n",
    "ACP = AdaptiveCP(0.1)\n",
    "inverse_ACP = inverse_AdaptedCP(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a simple absolute comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Total of weights must be finite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m inverse_dict \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoverge\u001b[39m\u001b[38;5;124m'\u001b[39m:[], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m:[]}\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(normal_data):\n\u001b[1;32m----> 6\u001b[0m     vanila \u001b[38;5;241m=\u001b[39m \u001b[43mACP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAwACI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.05\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     adapted \u001b[38;5;241m=\u001b[39m inverse_ACP\u001b[38;5;241m.\u001b[39mAwACI(data, nu_sigma\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.01\u001b[39m, \u001b[38;5;241m0.05\u001b[39m))\n\u001b[0;32m      9\u001b[0m     vanila_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoverge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(vanila[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrealised_interval_coverage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\tobyw\\Documents\\ChrisPython\\ConformalProject\\src\\ConformalMethods\\AdaptiveCP.py:325\u001b[0m, in \u001b[0;36mAdaptiveCP.AwACI\u001b[1;34m(self, timeseries_data, interval_candidates, nu_sigma, gamma, title)\u001b[0m\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m \u001b[38;5;66;03m# You could but the return statement here\u001b[39;00m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;66;03m# Choosing which head to use.\u001b[39;00m\n\u001b[1;32m--> 325\u001b[0m chosen_set \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval_probabilites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Using random module as numpy can not deal with tuples.\u001b[39;00m\n\u001b[0;32m    326\u001b[0m conformal_sets_list\u001b[38;5;241m.\u001b[39mappend(chosen_set)\n\u001b[0;32m    327\u001b[0m chosen_interval_index\u001b[38;5;241m.\u001b[39mappend(head_sets\u001b[38;5;241m.\u001b[39mindex(chosen_set))\n",
      "File \u001b[1;32mc:\\Users\\tobyw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:485\u001b[0m, in \u001b[0;36mRandom.choices\u001b[1;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal of weights must be greater than zero\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _isfinite(total):\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal of weights must be finite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    486\u001b[0m bisect \u001b[38;5;241m=\u001b[39m _bisect\n\u001b[0;32m    487\u001b[0m hi \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Total of weights must be finite"
     ]
    }
   ],
   "source": [
    "# For the random data\n",
    "vanila_dict = {'coverge':[], 'width':[]}\n",
    "inverse_dict = {'coverge':[], 'width':[]}\n",
    "\n",
    "for i, data in enumerate(normal_data):\n",
    "    vanila = ACP.AwACI(data, nu_sigma=(10, 0.05))\n",
    "    adapted = inverse_ACP.AwACI(data, nu_sigma=(0.01, 0.05))\n",
    "\n",
    "    vanila_dict['coverge'].append(vanila['realised_interval_coverage'])\n",
    "    vanila_dict['width'].append(vanila['average_prediction_interval'])\n",
    "\n",
    "    inverse_dict['coverge'].append(adapted['realised_interval_coverage'])\n",
    "    inverse_dict['width'].append(adapted['average_prediction_interval'])\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "\n",
    "# Computing the averages and printing.\n",
    "vanila_coverage = np.mean(vanila_dict['coverge'])\n",
    "vanila_width = np.mean(vanila_dict['width'])\n",
    "\n",
    "inverse_coverage = np.mean(inverse_dict['coverge'])\n",
    "inverse_width = np.mean(inverse_dict['width'])\n",
    "\n",
    "print('\\n')\n",
    "print('Vanila average:', vanila_coverage, vanila_width)\n",
    "print('Inverse average:', inverse_coverage, inverse_width)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing for the stock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Total of weights must be finite",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, data \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(stock_data):\n\u001b[0;32m      6\u001b[0m     vanila \u001b[38;5;241m=\u001b[39m ACP\u001b[38;5;241m.\u001b[39mAwACI(data)\n\u001b[1;32m----> 7\u001b[0m     adapted \u001b[38;5;241m=\u001b[39m \u001b[43minverse_ACP\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAwACI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnu_sigma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.15\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     vanila_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoverge\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(vanila[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrealised_interval_coverage\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     10\u001b[0m     vanila_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwidth\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(vanila[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_prediction_interval\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\tobyw\\Documents\\ChrisPython\\ConformalProject\\src\\ConformalMethods\\AdaptiveCP.py:322\u001b[0m, in \u001b[0;36mAdaptiveCP.AwACI\u001b[1;34m(self, timeseries_data, interval_candidates, nu_sigma, gamma, title)\u001b[0m\n\u001b[0;32m    319\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m \u001b[38;5;66;03m# You could but the return statement here\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;66;03m# Choosing which head to use.\u001b[39;00m\n\u001b[1;32m--> 322\u001b[0m chosen_set \u001b[38;5;241m=\u001b[39m \u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhead_sets\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterval_probabilites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;66;03m# Using random module as numpy can not deal with tuples.\u001b[39;00m\n\u001b[0;32m    323\u001b[0m conformal_sets_list\u001b[38;5;241m.\u001b[39mappend(chosen_set)\n\u001b[0;32m    324\u001b[0m chosen_interval_index\u001b[38;5;241m.\u001b[39mappend(head_sets\u001b[38;5;241m.\u001b[39mindex(chosen_set))\n",
      "File \u001b[1;32mc:\\Users\\tobyw\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\random.py:485\u001b[0m, in \u001b[0;36mRandom.choices\u001b[1;34m(self, population, weights, cum_weights, k)\u001b[0m\n\u001b[0;32m    483\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal of weights must be greater than zero\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    484\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _isfinite(total):\n\u001b[1;32m--> 485\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal of weights must be finite\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    486\u001b[0m bisect \u001b[38;5;241m=\u001b[39m _bisect\n\u001b[0;32m    487\u001b[0m hi \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Total of weights must be finite"
     ]
    }
   ],
   "source": [
    "# For the random data\n",
    "vanila_dict = {'coverge':[], 'width':[]}\n",
    "inverse_dict = {'coverge':[], 'width':[]}\n",
    "\n",
    "for i, data in enumerate(stock_data):\n",
    "    vanila = ACP.AwACI(data)\n",
    "    adapted = inverse_ACP.AwACI(data, nu_sigma=(10, 0.15))\n",
    "\n",
    "    vanila_dict['coverge'].append(vanila['realised_interval_coverage'])\n",
    "    vanila_dict['width'].append(vanila['average_prediction_interval'])\n",
    "\n",
    "    inverse_dict['coverge'].append(adapted['realised_interval_coverage'])\n",
    "    inverse_dict['width'].append(adapted['average_prediction_interval'])\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "\n",
    "# Computing the averages and printing.\n",
    "vanila_coverage = np.mean(vanila_dict['coverge'])\n",
    "vanila_width = np.mean(vanila_dict['width'])\n",
    "\n",
    "inverse_coverage = np.mean(inverse_dict['coverge'])\n",
    "inverse_width = np.mean(inverse_dict['width'])\n",
    "\n",
    "print('\\n')\n",
    "print('Vanila average:', vanila_coverage, vanila_width)\n",
    "print('Inverse average:', inverse_coverage, inverse_width)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
